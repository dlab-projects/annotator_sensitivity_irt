{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_lego as mplego\n",
    "import pandas as pd\n",
    "\n",
    "from hatespeech import keys, utils\n",
    "from scipy.stats import bootstrap, mannwhitneyu\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mplego.style.use_latex_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9367dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"~/data/hatespeech/unfiltered_ratings.feather\"\n",
    "rater_quality_path = \"~/data/hatespeech/rater_quality_check.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d028ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in hate speech data\n",
    "data = pd.read_feather(data_path)\n",
    "# Remove all rows in which some item is missing\n",
    "data = utils.filter_missing_items(data)\n",
    "# Remove all rows in which the rater is not up to sufficient quality\n",
    "rater_quality = pd.read_csv(rater_quality_path)\n",
    "data = utils.filter_annotator_quality(data, rater_quality)\n",
    "# Recode item responses\n",
    "data = utils.recode_responses(\n",
    "    data,\n",
    "    insult={1: 0, 2: 1, 3: 2, 4: 3},\n",
    "    humiliate={1: 0, 2: 0, 3: 1, 4: 2},\n",
    "    status={1: 0, 2: 0, 3: 1, 4: 1},\n",
    "    dehumanize={1: 0, 2: 0, 3: 1, 4: 1},\n",
    "    violence={1: 0, 2: 0, 3: 1, 4: 1},\n",
    "    genocide={1: 0, 2: 0, 3: 1, 4: 1},\n",
    "    attack_defend={1: 0, 2: 1, 3: 2, 4: 3},\n",
    "    hatespeech={1: 0, 2: 1})\n",
    "# Maximum values for each survey item\n",
    "norms = {\n",
    "    'sentiment': 4,\n",
    "    'respect': 4,\n",
    "    'insult': 3,\n",
    "    'humiliate': 2,\n",
    "    'status': 1,\n",
    "    'dehumanize': 1,\n",
    "    'violence': 1,\n",
    "    'genocide': 1,\n",
    "    'attack_defend': 3,\n",
    "    'hatespeech': 1\n",
    "}\n",
    "# Labels\n",
    "labels = {\n",
    "    'sentiment': 'Sentiment',\n",
    "    'respect': '(Dis)respect',\n",
    "    'insult': 'Insult',\n",
    "    'humiliate': 'Humiliate',\n",
    "    'status': 'Status',\n",
    "    'dehumanize': 'Dehumanize',\n",
    "    'violence': 'Violence',\n",
    "    'genocide': 'Genocide',\n",
    "    'attack_defend': 'Attack/Defend',\n",
    "    'hatespeech': 'Hate Speech'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ec1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reference set\n",
    "reference_set = data[data['platform'] == 'reference'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of unique reference set comments: {reference_set[\"comment_id\"].unique().size}')\n",
    "print(f'Number of samples in reference set: {reference_set.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6dfb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black/white targeting comments by black/white annotators\n",
    "bw_targets = ['target_race_black', 'target_race_white']\n",
    "reference_bw = utils.filter_annotator_identity(reference_set, ['annotator_race_black', 'annotator_race_white'])\n",
    "bw_agreement, reference_targeting_bw = utils.get_comments_w_agreement_on_target(\n",
    "    data=reference_bw,\n",
    "    targets=bw_targets,\n",
    "    threshold=0.5,\n",
    "    suffix='_label')\n",
    "targeting_black = reference_targeting_bw[reference_targeting_bw['target_race_black_label']].copy()\n",
    "# Add in annotator label\n",
    "targeting_black['annotator_race'] = np.where(targeting_black['annotator_race_black'], 'black', 'white')\n",
    "# Calculate differences along black/white annotators\n",
    "bw_diffs = targeting_black.groupby(['comment_id', 'annotator_race']).mean()[keys.items]\n",
    "bw_mean_diffs = bw_diffs.diff().query(\"annotator_race == 'white'\").droplevel('annotator_race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a47665-343a-4681-89ba-6ed474109ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_comment_id = 20032\n",
    "race_comment = targeting_black[targeting_black['comment_id'] == race_comment_id]\n",
    "print(f\"Comment #{race_comment_id}:\",\n",
    "      race_comment.drop_duplicates('comment_id').raw_text.values[0])\n",
    "black_ratings = race_comment[race_comment['annotator_race'] == 'black'][keys.items]\n",
    "white_ratings = race_comment[race_comment['annotator_race'] == 'white'][keys.items]\n",
    "mean_black_ratings = black_ratings.mean()\n",
    "mean_white_ratings = white_ratings.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911cfe9-3b32-479f-a4a9-42085e9e7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in keys.items:\n",
    "    print(item, mannwhitneyu(black_ratings[item], white_ratings[item], alternative='greater').pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db88f56-8c97-4de8-a058-4a9eb69e0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Men/white targeting comments by black/white annotators\n",
    "mw_targets = ['target_gender_women', 'target_gender_men']\n",
    "reference_mw = utils.filter_annotator_identity(reference_set, ['annotator_gender_men', 'annotator_gender_women'])\n",
    "bw_agreement, reference_targeting_mw = utils.get_comments_w_agreement_on_target(\n",
    "    data=reference_mw,\n",
    "    targets=mw_targets,\n",
    "    threshold=0.5,\n",
    "    suffix='_label')\n",
    "targeting_women = reference_targeting_mw[reference_targeting_mw['target_gender_women_label']].copy()\n",
    "# Add in annotator label\n",
    "targeting_women['annotator_gender'] = np.where(targeting_women['annotator_gender_women'], 'woman', 'man')\n",
    "# Calculate differences along black/white annotators\n",
    "mw_diffs = targeting_women.groupby(['comment_id', 'annotator_gender']).mean()[keys.items]\n",
    "mw_mean_diffs = mw_diffs.diff().query(\"annotator_gender == 'man'\").droplevel('annotator_gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da418c2-cb66-4f96-9f25-3434946d8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_comment_id = 20044\n",
    "gender_comment = targeting_women[targeting_women['comment_id'] == gender_comment_id]\n",
    "print(f\"Comment #{gender_comment_id}:\",\n",
    "      gender_comment.drop_duplicates('comment_id').raw_text.values[0])\n",
    "men_ratings = gender_comment[gender_comment['annotator_gender'] == 'man'][keys.items]\n",
    "women_ratings = gender_comment[gender_comment['annotator_gender'] == 'woman'][keys.items]\n",
    "mean_men_ratings = men_ratings.mean()\n",
    "mean_women_ratings = women_ratings.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in keys.items:\n",
    "    print(item, mannwhitneyu(men_ratings[item], women_ratings[item], alternative='less').pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_kw = {'capsize': 4,\n",
    "            'lw': 2}\n",
    "\"\"\"\n",
    "Figure 1\n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "plot_items = ['respect', 'insult', 'humiliate', 'violence', 'hatespeech']\n",
    "n_plot_items = len(plot_items)\n",
    "plot_norms = [norms[item] for item in plot_items]\n",
    "plot_labels = [labels[item] for item in plot_items]\n",
    "plot_labels\n",
    "black_errors = [bootstrap([black_ratings[item]], np.mean, method='basic').standard_error / norms[item]\n",
    "                for item in plot_items]\n",
    "white_errors = [bootstrap([white_ratings[item]], np.mean, method='basic').standard_error / norms[item]\n",
    "                for item in plot_items]\n",
    "women_errors = [bootstrap([women_ratings[item]], np.mean, method='basic').standard_error / norms[item]\n",
    "                for item in plot_items]\n",
    "men_errors = [bootstrap([women_ratings[item]], np.mean, method='basic').standard_error / norms[item]\n",
    "              for item in plot_items]\n",
    "\n",
    "width = 0.3\n",
    "gap = 0.15\n",
    "# Race plot\n",
    "axes[0].bar(np.arange(5) - gap,\n",
    "            mean_black_ratings[plot_items] / plot_norms,\n",
    "            width=width,\n",
    "            yerr=black_errors,\n",
    "            label='Black Annotator',\n",
    "            color='C0',\n",
    "            error_kw=error_kw)\n",
    "axes[0].bar(np.arange(5) + gap,\n",
    "            mean_white_ratings[plot_items] / plot_norms,\n",
    "            width=width,\n",
    "            yerr=white_errors,\n",
    "            label='White Annotator',\n",
    "            color='C1',\n",
    "            error_kw=error_kw)\n",
    "axes[0].text(x=0, y=1.02,\n",
    "             s='*',\n",
    "             ha='center',\n",
    "             va='center',\n",
    "             fontsize=25)\n",
    "axes[0].text(x=1, y=1.02,\n",
    "             s='**',\n",
    "             ha='center',\n",
    "             va='center',\n",
    "             fontsize=25)\n",
    "axes[0].text(x=2, y=1.02,\n",
    "             s='*',\n",
    "             ha='center',\n",
    "             va='center',\n",
    "             fontsize=25)\n",
    "axes[0].text(x=4, y=1.02,\n",
    "             s='***',\n",
    "             ha='center',\n",
    "             va='center',\n",
    "             fontsize=25)\n",
    "             \n",
    "# Gender plot\n",
    "axes[1].bar(np.arange(5) - gap,\n",
    "            mean_women_ratings[plot_items] / plot_norms,\n",
    "            width=width,\n",
    "            yerr=women_errors,\n",
    "            label='Female Annotator',\n",
    "            color='C2',\n",
    "            error_kw=error_kw)\n",
    "axes[1].bar(np.arange(5) + gap,\n",
    "            mean_men_ratings[plot_items] / plot_norms,\n",
    "            width=width,\n",
    "            yerr=men_errors,\n",
    "            label='Male Annotator',\n",
    "            color='C5',\n",
    "            error_kw=error_kw)\n",
    "\n",
    "axes[1].text(x=0, y=1.02,\n",
    "             s='***',\n",
    "             ha='center',\n",
    "             va='center',\n",
    "             fontsize=25)\n",
    "axes[1].text(x=1, y=1.02,\n",
    "             s='***',\n",
    "             ha='center',\n",
    "             va='center',\n",
    "             fontsize=25)\n",
    "axes[1].text(x=2, y=1.02,\n",
    "             s='**',\n",
    "             ha='center',\n",
    "             va='center',\n",
    "             fontsize=25)\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks(np.arange(n_plot_items))\n",
    "    ax.set_xticklabels(mplego.labels.bold_text(plot_labels),\n",
    "                       ha='right',\n",
    "                       rotation=20)\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    ax.set_xlabel(mplego.labels.bold_text('Survey Item'), fontsize=18)\n",
    "    ax.set_ylabel(mplego.labels.bold_text('Normalized Rating'), fontsize=18)\n",
    "    ax.legend(bbox_to_anchor=(0., 1.02, 1, 0.2),\n",
    "              loc=\"lower left\",\n",
    "              mode=\"expand\",\n",
    "              borderaxespad=0,\n",
    "              prop={'size': 15},\n",
    "              ncol=2)\n",
    "    \n",
    "axes[0].set_title(mplego.labels.bold_text(\"``shut the f*** up you dumb black b****''\"),\n",
    "                  pad=45,\n",
    "                  fontsize=15)\n",
    "axes[1].set_title(mplego.labels.bold_text(\"``It's actually because men need to be funny to hook\\nup \"\n",
    "                                             \"with women. [...] I've heard great female comedians,\\n\"\n",
    "                                             \"but it's not hard to see why there are more male\\ncomedians. \"\n",
    "                                             \"Girls don't need to be funny to have sex.''\"),\n",
    "                  pad=45,\n",
    "                  fontsize=15)\n",
    "\n",
    "mplego.labels.apply_subplot_labels(axes, bold=True, size=25, x=-0.13, y=1.25)\n",
    "plt.savefig('figure1.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate",
   "language": "python",
   "name": "hate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
